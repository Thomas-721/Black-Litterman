{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies\n",
    "<small>\n",
    "\n",
    "This notebook defines the 4 strategies that will be incorporated in the black-litterman framework:\n",
    "- Momentum\n",
    "- Short term reversal\n",
    "- Short interest\n",
    "- ARIMA-GARCH\n",
    "\n",
    "Each strategy are backtested using the in-sample data. The weight dataframes corresponding to each strategy are saved as csv for later use. \n",
    "<small/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from arch import arch_model\n",
    "import pmdarima\n",
    "from utils.backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "price_df = pd.read_csv('data/price.csv', index_col='Date', parse_dates=True).shift(1)\n",
    "volume_df = pd.read_csv('data/volume.csv', index_col='Date', parse_dates=True).shift(1)\n",
    "short_interest_df = pd.read_csv('data/short_interest.csv', index_col='Date', parse_dates=True, dtype=float).shift(1)\n",
    "benchmark_df = pd.read_csv('data/benchmark.csv', index_col='Date', parse_dates=True).shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum\n",
    "short_momentum = price_df.pct_change(periods=21, fill_method=None)\n",
    "medium_momentum = price_df.pct_change(periods=105, fill_method=None).shift(periods=21)\n",
    "long_momentum = price_df.pct_change(periods=231, fill_method=None).shift(periods=21)\n",
    "weight_df = (short_momentum.loc[long_momentum.index] + medium_momentum.loc[long_momentum.index] + long_momentum)\n",
    "\n",
    "for date in weight_df.index:\n",
    "    vol = volume_df.loc[date]\n",
    "    upper_vol = vol[vol >= vol.quantile(0.8)]\n",
    "\n",
    "    r = weight_df.loc[date, upper_vol.index]\n",
    "    upper_r_symbols = r[r >= r.quantile(0.8)].index\n",
    "\n",
    "    weight_df.loc[date, :] = 0\n",
    "    weight_df.loc[date, upper_r_symbols] = 1\n",
    "\n",
    "weight_df = weight_df.div(weight_df.sum(axis=1), axis=0).dropna(how='all')\n",
    "weight_df = weight_df.groupby(pd.Grouper(freq='ME')).tail(1)\n",
    "weight_df.to_csv('weight/momentum.csv')\n",
    "\n",
    "backtest = Backtest(weight_df)\n",
    "backtest.run(transaction_cost=0)\n",
    "backtest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short term reversal\n",
    "return_df = price_df.groupby(pd.Grouper(freq='ME')).tail(1).pct_change(fill_method=None).dropna(how=\"all\")\n",
    "volume_change_df = volume_df.groupby(pd.Grouper(freq='ME')).mean().pct_change(fill_method=None).dropna(how=\"all\")\n",
    "volume_change_df.index = return_df.index\n",
    "weight_df = return_df.copy()\n",
    "\n",
    "for date in weight_df.index:\n",
    "    vol = volume_change_df.loc[date]\n",
    "    bottom_vol = vol[vol <= vol.quantile(0.1)]\n",
    "\n",
    "    r = return_df.loc[date, bottom_vol.index]\n",
    "    bottom_r_symbols = r[r <= r.quantile(0.1)].index\n",
    "        \n",
    "    weight_df.loc[date, :] = 0\n",
    "    weight_df.loc[date, bottom_r_symbols] = 1\n",
    "\n",
    "weight_df = weight_df.div(weight_df.sum(axis=1), axis=0).dropna(how='all')\n",
    "weight_df.to_csv('weight/reversal.csv')\n",
    "\n",
    "backtest = Backtest(weight_df)\n",
    "backtest.run()\n",
    "backtest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short interest\n",
    "weight_df = short_interest_df.copy()\n",
    "period_ends = weight_df.index\n",
    "period_starts = pd.Index([volume_df.index[0]]).append(weight_df.index[:-1] + pd.Timedelta(days=1))\n",
    "for start_date, end_date in zip(period_starts, period_ends):\n",
    "    weight_df.loc[end_date] = weight_df.loc[end_date].div(volume_df.loc[start_date:end_date].mean())\n",
    "    \n",
    "lower = weight_df.apply(lambda x: x.quantile(0.05), axis=1)\n",
    "weight_df = pd.DataFrame(np.where(weight_df.lt(lower, axis=0), 1, 0), \n",
    "                         index=weight_df.index,  \n",
    "                         columns=weight_df.columns)\n",
    "\n",
    "weight_df = weight_df.div(weight_df.sum(axis=1), axis=0).dropna(how=\"all\")\n",
    "weight_df.to_csv('weight/shortinterest.csv')\n",
    "\n",
    "backtest = Backtest(weight_df)\n",
    "backtest.run()\n",
    "backtest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA-GARCH \n",
    "# This block of code takes around 2 hours to run\n",
    "return_df = price_df.pct_change(fill_method=None)\n",
    "\n",
    "arima_results, garch_results = [], []\n",
    "month_end = return_df.iloc[500:].groupby(pd.Grouper(freq='ME')).tail(1).index\n",
    "for date in tqdm(month_end):\n",
    "    current_index = return_df.index.get_loc(date)\n",
    "\n",
    "    # For each rebalancing period, conduct PCA to reduce dimensionality\n",
    "    r = return_df.iloc[current_index-500:current_index]\n",
    "    cov = r.cov()\n",
    "\n",
    "    cov_eigval, cov_eigvec = np.linalg.eig(cov)\n",
    "    idx = cov_eigval.argsort()[::-1]\n",
    "    cov_eigval = cov_eigval[idx]    \n",
    "    cov_eigvec = cov_eigvec[:, idx]\n",
    "\n",
    "    pc_stock = []\n",
    "    for i in range(20):\n",
    "        mask = np.ones(len(cov), dtype=bool)\n",
    "        mask[pc_stock] = False\n",
    "        pc_stock.append(np.argmax(np.abs(cov_eigvec[i])[mask]))\n",
    "\n",
    "    # Fit ARIMA-GARCH models for each period\n",
    "    data = [r[col].dropna().values if i in pc_stock else pd.DataFrame() for i, col in enumerate(return_df.columns)]\n",
    "    \n",
    "    arima_res = [pmdarima.auto_arima(df) if len(df) > 0 else None for df in data]\n",
    "    arima_results.append(arima_res)\n",
    "\n",
    "    garch_models = [arch_model(res.resid(), vol='Garch', p=1, q=1, lags=1) if res != None else None for res in arima_res]\n",
    "    garch_res = [model.fit(disp=\"off\") if model is not None else None for model in garch_models]\n",
    "    garch_results.append(garch_res)\n",
    "\n",
    "# forecast with the fitted model\n",
    "mean_forecast = []\n",
    "var_forecast = []\n",
    "for arima, garch in tqdm(zip(arima_results, garch_results)):\n",
    "    mean_forecast.append([np.mean(res.predict(n_periods=21)) if res != None else np.nan for res in arima])\n",
    "    var_forecast.append([np.mean(res.forecast(horizon=21).variance) if res != None else np.nan for res in garch])\n",
    "\n",
    "mean_df = pd.DataFrame(mean_forecast, index=month_end, columns=return_df.columns)\n",
    "variance_df = pd.DataFrame(var_forecast, index=month_end, columns=return_df.columns)\n",
    "\n",
    "# Calculate the weights\n",
    "weight_df = mean_df.div(variance_df)\n",
    "weight_df = weight_df.clip(lower=0).fillna(0)\n",
    "weight_df = weight_df.div(weight_df.sum(axis=1), axis=0).dropna(how='all')\n",
    "weight_df.to_csv('weight/timeseries.csv')\n",
    "\n",
    "backtest = Backtest(weight_df)\n",
    "backtest.run()\n",
    "backtest.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
