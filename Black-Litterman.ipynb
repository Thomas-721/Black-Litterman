{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black-Litterman\n",
    "<small>\n",
    "\n",
    "This notebook combines the separate strategies into a single portfolio via the Black-Litterman model.  \n",
    "The implementation is based on the paper by Idzorek, Thomas M. \"A Step-By-Step Guide to the Black-Litterman Model.\"\n",
    "<small/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from utils.backtest import Backtest\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "price_df = pd.read_csv('data/price.csv', index_col='Date', parse_dates=True).shift(1)\n",
    "market_cap_df = pd.read_csv('data/market_cap.csv', index_col='Date', parse_dates=True).shift(1)\n",
    "\n",
    "rf_df = pd.read_csv('data/rf_rate.csv', index_col=0, parse_dates=True).shift(1)\n",
    "rf_df = (rf_df/100 + 1)  ** (1/252) - 1\n",
    "\n",
    "all_files = os.listdir(\"weight\")\n",
    "weight_files = [f for f in all_files if f.endswith(\".csv\")]\n",
    "weight_dfs = [pd.read_csv(os.path.join(\"weight\", file), index_col=0, parse_dates=True) for file in weight_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Litterman model\n",
    "return_df = price_df.pct_change(fill_method=None)\n",
    "month_end = return_df.iloc[500:].groupby(pd.Grouper(freq='ME')).tail(1).index\n",
    "month_end = [date for date in month_end if date in market_cap_df.index]\n",
    "\n",
    "results = {}\n",
    "pp = None\n",
    "for date in tqdm(month_end):\n",
    "    current_index = return_df.index.get_loc(date)\n",
    "\n",
    "    # Implied Excess Equilibrium Return \n",
    "    r = return_df.iloc[current_index-500:current_index+1]\n",
    "    excess_r = r - rf_df.loc[r.index].values\n",
    "\n",
    "    w_mkt = market_cap_df.loc[date] / sum(market_cap_df.loc[date])\n",
    "    sigma = r.cov().values\n",
    "    lambd = np.dot(w_mkt, excess_r.mean()) / np.dot(np.dot(w_mkt, sigma), w_mkt)\n",
    "    pi = lambd * np.dot(sigma, w_mkt).reshape(-1, 1)\n",
    "    \n",
    "    # Views\n",
    "    P = []\n",
    "    for df in weight_dfs:\n",
    "        if date in df.index:\n",
    "            w_vector = df.loc[date]\n",
    "            m = (w_vector == 0).sum()\n",
    "            w_vector[w_vector == 0] = -1/m\n",
    "            P.append(w_vector)\n",
    "    P = np.array(P)\n",
    "\n",
    "    #Q = np.ones((P.shape[0],1))\n",
    "    Q = (pp - pp.min())/ (pp.max() - pp.min()) if pp is not None and len(pp) == P.shape[0] else np.ones((P.shape[0],1))\n",
    "    omega = np.diag([row @ sigma @ row for row in P])\n",
    "    pp = np.expand_dims((P @ r.T + 1).prod(axis=1), axis=1)\n",
    "    \n",
    "    # Combined Return Distribution \n",
    "    tau = 0.05\n",
    "    inv_sigma = np.linalg.inv(tau * sigma)\n",
    "    inv_omega = np.linalg.inv(omega) \n",
    "    E_r = np.linalg.inv(inv_sigma + P.T @ inv_omega @ P) @ ((inv_sigma @ pi) + (P.T @ inv_omega @ Q))\n",
    "\n",
    "    # Use the Combined Return Distribution in a mean-variance optimizer\n",
    "    def sharpe_objective(w, mu, sigma, rf):\n",
    "        w_mu = np.dot(w, mu)\n",
    "        w_sigma_w = np.sqrt(np.dot(w.T, np.dot(sigma, w)))\n",
    "        return - (w_mu - rf) / w_sigma_w\n",
    "\n",
    "    mu = E_r\n",
    "    sigma = r.cov()\n",
    "    rf = rf_df.loc[date]\n",
    "    initial_guess = len(mu) * [1 / len(mu)]\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = [(0, 1) for _ in range(len(mu))]\n",
    "\n",
    "    res = minimize(sharpe_objective, initial_guess, args=(mu, sigma, rf), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    results[date] = res.x\n",
    "\n",
    "weight_df = pd.DataFrame.from_dict(results, orient='index', columns=return_df.columns)\n",
    "\n",
    "backtest = Backtest(weight_df)\n",
    "backtest.run()\n",
    "backtest.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
